---
layout: post
title: "hadoop-命令参数介绍"
category : hadoop
tags : [bigData, hadoop]
---

	hadoop fs :       
	[-ls <path>] hadoop fs -ls /user 显示/user路径下的文件及文件夹
	[-lsr <path>] 迭代显示路径下的所有文件及文件夹
	[-du <path>] 命令显示目录中所有文件的大小,或者当只指定一个文件时,显示此文件的大小
	[-dus <path>] 显示文件的大小
	[-df]显示Hadoop所使用的文件系统的大小 hadoop fs -df <path>  
	[-count[-q] <path>]
	[-mv <src> <dst>]将文件从源路径移动到目标路径。这个命令允许有多个源路径，此时目标路径必须是一个目录。不允许在不同的文件系统间移动文件。 
	[-cp <src> <dst>] 将文件从源路径复制到目标路径。这个 Hadoop Shell 命令允许有多个源路径,此时目标路径必须是一个目录
	[-rm [-skipTrash] <path>]删除指定的文件。只删除非空目录和文件
    [-rmr [-skipTrash] <path>]delete的递归版本。
	[-put <localsrc> ... <dst>]从本地文件系统中复制单个或多个源路径到目标文件系统。也支持从标准输入中读取输入写入目标文件系统。
	[-copyFromLocal <localsrc> ... <dst>] 除了限定源路径是一个本地文件外,和 put 命令相似
	[-moveFromLocal <localsrc> ... <dst>] dfs -moveFromLocal <src> <dst>
 
	[-getmerge <src> <localdst> [addnl]] 接受一个源目录和一个目标文件作为输入，并且将源目录中所有的文件连接成本地目标文件。addnl是可选的，用于指定在每个文件结尾添加一个换行符
	[-cat <src>]     查看路径指定文件的内容
	[-text <src>]将源文件输出为文本格式。允许的格式是zip和TextRecordInputStream
	[-copyToLocal [-ignoreCrc] [-crc] <src> <localdst>] 除了限定目标路径是一个本地文件外,和 get 命令类似
	[-moveToLocal [-crc] <src> <localdst>]
	[-mkdir <path>] 接受路径指定的uri作为参数，创建这些目录
	[-tail [-f] <file>]将文件尾部1K字节的内容输出到stdout。支持-f选项，行为和Unix中一致
	[-chmod [-R] <MODE[,MODE]..| OCTALMODE> PATH..] 改变文件的权限。使用-R将使改变在目录结构下递归进行 hadoop fs -chmod
	[-chown [-R] [OWNER][:[GROUP]] PATH...]改变文件的拥有者。使用-R将使改变在目录结构下递归进行
	[-chgrp [-R] GROUP PATH...] 改变文件所属的组 使用-R将使改变在目录结构下递归进行
	[-expunge ] 清空回收站。请参考 HDFS 设计文档以获取更多关于回收站特性的信息。 使用方法:hadoop fs -expunge
	[get [-ignorecrc][-crc]<src><localdst>]复制文件到本地文件系统。可用-ignorecrc 选项复制 CRC 校验失败的文件。使用-crc 选项
	[setrep ]hadoop fs -setrep [-R] <path> 改变一个文件的副本系数。-R选项用于递归改变目录下所有文件的副本系数
	[stat] hadoop fs -stat URI [URI …]  返回指定路径的统计信息
	[test] hadoop fs -test -[ezd] URI
	[touchz ] 使用方法：hadoop fs -touchz URI [URI …] 创建一个0字节的空文件
	[-help [cmd]]
	distcp <srcurl> <desturl> 递归地复制文件或者目录 hadoop distcp /xxx1  /xxx2

	hadoop fs -count /xj
	2      1    108 hdfs://xxx:9000/xj


第一个数值2表示/sunwg下的文件夹的个数，

第二个数值1表是当前文件夹下文件的个数，

第三个数值108表示该文件夹下文件所占的空间大小，这个大小是不计算副本的个数的

	hadoop fs -count -q /xj
	1024         1021 10240 10132       2      1    108 hdfs://xxx:9000/xj
在count后面增加-q选项可以查看当前文件夹的限额使用情况

第一个数值1024，表示总的文件包括文件夹的限额

第二个数值1021表示目前剩余的文件限额，即还可以创建这么多的文件或文件夹

第三个数值10240表示当前文件夹空间的限额

第四个数值10132表示当前文件夹可用空间的大小，这个限额是会计算多个副本的

剩下的三个数值与-count的结果一样

	hadoop fs -test -[ezd] URI
选项：
-e 检查文件是否存在。如果存在则返回0。

-z 检查文件是否是0字节。如果是则返回0。

-d 如果路径是个目录，则返回1，否则返回0。

示例：hadoop fs -test -e filename 

