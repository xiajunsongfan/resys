---
layout: post
title: "HADOOP集群安装 Linux"
category : hadoop
tags : [bigData, hadoop]
---
author : xiajun


通常，集群里的一台机器被指定为 NameNode，另一台不同的机器被指定为JobTracker。这些机器是masters。余下的机器即作为DataNode也作为TaskTracker。这些机器是slaves

官方地址：([http://hadoop.apache.org/common/docs/r0.19.2/cn/cluster_setup.html](http://hadoop.apache.org/common/docs/r0.19.2/cn/cluster_setup.html))

1.确保在你集群中的每个节点上都安装了所有必需软件：JDK，ssh，Hadoop

2.准备机器：一台master，若干台slave，配置每台机器的/etc/hosts保证各台机器之间通过机器名可以互访，例如：

    10.64.56.1 node1（master）   
    10.64.56.2 node2 （slave1）   
    10.64.56.3 node3 （slave2）

	机器名              IP地址           作用

	master            10.64.56.1    NameNode、JobTracker
	slave1             10.64.56.2     DataNode、TaskTracker
	slave2             10.64.56.78   DataNode、TaskTracker
3.创建HADOOP用户

    $ useradd hadoop
4.在所有的机器上都建立相同的目录：/home/hadoop/hadoop1.0

5.设置所有机器之间的ssh为无需密码的、自动登录

	$ ssh-keygen -t rsa
然后一直按回车 完成后，在home跟目录下会产生隐藏文件夹.ssh

进入.ssh目录   

	cat id_rsa.pub >> authorized_keys 
 id_rsa.pub是本机的公钥，谁要无密码连接本机就需要将它复制的自己的authorized_keys里

 为了保证master可以无需密码自动登录到slave1和slave2，先在slave1和slave2上执行

	ssh -ketgen -t rsa
6.在master机器上 /home/hadoop/下解压hadoop (注意：切换到hadoop用户下)

7.修改hadoop1.0/conf/hadoop-env.sh 添加 export JAVA_HOME=java_home的目录

8.修改hadoop1.0/bin/hadoop-daemon.sh 添加 HADOOP_PID_DIR=/home/hadoop/hadoop1.0/tmp (注: tmp 需要自己新建)

9.修改配置文件：conf/core-site.xml

<?prettify lang=xml linenums=true?>
<pre class="prettyprint linenums" id="quine" style="border:4px solid #88c">
<xmp>
<?xml version="1.0"?>
<configuration>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://master:49000</value><!--master 可用IP代替 -->
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/hadoop/hadoop1.0/hadooptmp</value> <!-- 注意需要新建hadooptmp目录 -->
	</property>
	<property><!--Hadoop回收站trash，默认是关闭的,默认是0.单位分钟。这里我设置的是1天（60*24）-->
		<name>fs.trash.interval</name>
		<value>1440</value>
		<description>Number of minutes between trash checkpoints.
		If zero, the trash feature is disabled.
        </description>
	</property>
</configuration>

修改配置文件：conf/mapred-site.xml
<?xml version="1.0"?> 
<configuration> 
	<property> 
		<name>mapred.job.tracker</name> 
		<value>master:49001</value><!--master 可用IP代替 -->
	</property> 
	<property> 
		<name>mapred.local.dir</name> 
		<value>/home/hadoop/hadoop1.0/var</value><!-- 注意需要新建var目录 并附上可执行的权限 重要 -->
	</property> 
</configuration>

修改配置文件：conf/hdfs-site.xml
<?xml version="1.0"?>
<configuration>
	<property>
		<name>dfs.name.dir</name>
		<value>/home/hadoop/hadoop1.0/name1,/home/hadoop/hadoop1.0/name2</value>
		<description></description>
	</property>
	<property>
		<name>dfs.data.dir</name>
		<value>/home/hadoop/hadoop1.0/data1,/home/hadoop/hadoop1.0/data2</value>
		<description></description>
	</property>
	<property>
		<name>dfs.replication</name>
		<!-- 我们的集群又两个结点，所以rep两份 默认是3 -->
		<value>2</value>
	</property>
	<property>
        <name>dfs.datanode.max.xcievers</name>
        <value>4096</value><!--HDFS Datanode 同时打开文件个数的上限-->
    </property>
	<property>
        <name>dfs.socket.timeout</name><!-- 设置hsdf操作文件时的超时时间 如果有hbase最好将hbase的设置和这个一样 -->
        <value>3600000</value>
    </property>
	 <property>
        <name>dfs.datanode.socket.write.timeout</name>
        <value>3600000</value>
    </property>
</configuration>
</xmp>
</pre>
配置masters和slaves主从结点

修改conf/masters 添加 master的IP地址

修改conf/slaves   添加slave1，slave2的IP地址 注意：要一行一个ip

10.将修改后的hadoop整个目录拷贝到其他机器上/home/hadoop/hadoop1.0目录  注意:hadoop用户要新建 

11.防火墙可能会引起master和salve之间的通讯，建议关闭  sudo iptables stop

12.在master机器上执行./hadoop/hadoop1.0/bin/hadoop namenode -format 格式化文件系统

13.在master上启动hadoop ./bin/start-all.sh 这个命令将会启动本机及其slave上的所有hadoop服务

14.常见问题

 jobtracker.info could only be replicated to 0 nodes, instead of 1 一般由防火墙导致可关闭防火墙，也可是在namenode中配置master 和 jobtracker 的ip时使用的是localhost ，将这两个改成namenode以及jobtracker本机的实际ip。

15.常用命令

	./hadoop namenode -format;./hadoop fs -mkdir input;./hadoop fs -put /home/xxx.txt input;./hadoop fs -ls input;./hadoop fs -cat input/*;

	./hadoop dfs -rmr input;

	./hadoop job -list

	./jadoop job -kill jobid
16.常见错误

1> Hadoop运行mapreduce实例时,抛出错误 All datanodes xxx.xxx.xxx.xxx:xxx are bad. Aborting…
> 此错误是由于Linux下打开文件数大小限制，可以修改 /etc/security/limits.conf 添加一行

	* - nofile 2048
2>当一个HDFS系统同时处理许多个并行的put操作，往HDFS上传数据时，有时候会出现dfsclient 端发生socket 链接超时的报错，有的时候甚至会由于这种原因导致最终的put操作失败，造成数据上传不完整。
log类似如下：
>All datanodes  *** are bad. Aborting...

修改hdfs-site.xml

<?prettify lang=xml linenums=true?>
<pre class="prettyprint linenums" id="quine" style="border:4px solid #88c">
<xmp>
<property>
	<name>dfs.socket.timeout</name> <!--设置hdfs文件操作时的超时时间 -->
	<value>3600000</value>
</property>
<property>
	<name>dfs.datanode.socket.write.timeout</name>
	<value>3600000</value>
</property>
</xmp>
</pre>
