---
layout: post
title: "Linux下HADOOP集群安装"
category : hadoop
tags : [bigData, hadoop]
---
##Linux下HADOOP集群安装
**author : xiajun**
-
通常，集群里的一台机器被指定为 NameNode，另一台不同的机器被指定为JobTracker。这些机器是masters。余下的机器即作为DataNode也作为TaskTracker。这些机器是slaves

官方地址：([http://hadoop.apache.org/common/docs/r0.19.2/cn/cluster_setup.html](http://hadoop.apache.org/common/docs/r0.19.2/cn/cluster_setup.html))

1.确保在你集群中的每个节点上都安装了所有必需软件：JDK，ssh，Hadoop

2.准备机器：一台master，若干台slave，配置每台机器的/etc/hosts保证各台机器之间通过机器名可以互访，例如：

    10.64.56.1 node1（master）   
    10.64.56.2 node2 （slave1）   
    10.64.56.3 node3 （slave2）

	机器名              IP地址           作用

	master            10.64.56.1    NameNode、JobTracker
	slave1             10.64.56.2     DataNode、TaskTracker
	slave2             10.64.56.78   DataNode、TaskTracker
3.创建HADOOP用户

    $ useradd hadoop
4.在所有的机器上都建立相同的目录：/home/hadoop/hadoop1.0

5.设置所有机器之间的ssh为无需密码的、自动登录

	$ ssh-keygen -t rsa
然后一直按回车 完成后，在home跟目录下会产生隐藏文件夹.ssh

进入.ssh目录   

	cat id_rsa.pub >> authorized_keys 
 id_rsa.pub是本机的公钥，谁要无密码连接本机就需要将它复制的自己的authorized_keys里

 为了保证master可以无需密码自动登录到slave1和slave2，先在slave1和slave2上执行

	ssh -ketgen -t rsa
6.在master机器上 /home/hadoop/下解压hadoop (注意：切换到hadoop用户下)

7.修改hadoop1.0/conf/hadoop-env.sh 添加 export JAVA_HOME=java_home的目录

8.修改hadoop1.0/bin/hadoop-daemon.sh 添加 HADOOP_PID_DIR=/home/hadoop/hadoop1.0/tmp (注: tmp 需要自己新建)

9.修改配置文件：conf/core-site.xml
<pre><xmp>
	<?xml version="1.0"?>              
    <?xml-stylesheet type="text/xsl"href="configuration.xsl"?>              
    <configuration>              
		<property>              
			<name>fs.default.name</name>              
			<value>hdfs://master:49000</value>     <!--master 可用IP代替 -->    
		</property>              
		<property>              
			<name>hadoop.tmp.dir</name>              
			<value>/home/hadoop/hadoop1.0/hadooptmp</value> <!-- 注意需要新建hadooptmp目录 -->
		</property>              
	</configuration>

	修改配置文件：conf/mapred-site.xml
	<?xmlversion="1.0"?>               
    <?xml-stylesheettype="text/xsl" href="configuration.xsl"?>               
	<configuration>               
		<property>               
			<name>mapred.job.tracker</name>               
			<value>master:49001</value>           <!--master 可用IP代替 -->   
		</property>               
		<property>               
			<name>mapred.local.dir</name>               
			<value>/home/hadoop/hadoop1.0/var</value>   <!-- 注意需要新建var目录 并附上可执行的权限 重要 -->
		</property>               
	</configuration>

	修改配置文件：conf/hdfs-site.xml
	<?xmlversion="1.0"?>            
	<?xml-stylesheettype="text/xsl" href="configuration.xsl"?>            
	<configuration>            
		<property>            
			<name>dfs.name.dir</name>            
			<value>/home/hadoop/hadoop1.0/name1,/home/hadoop/hadoop1.0/name2</value>           
			<description>  </description>            
		</property>            
		<property>            
			<name>dfs.data.dir</name>            
			<value>/home/hadoop/hadoop1.0/data1,/home/hadoop/hadoop1.0/data2</value>            
			<description> </description>            
		</property>            
		<property>            
			<name>dfs.replication</name>            
			<!-- 我们的集群又两个结点，所以rep两份 默认是3 -->
			<value>2</vaue>            
		</property>            
	</configuration>
</xmp></pre>
配置masters和slaves主从结点

修改conf/masters 添加 master的IP地址

修改conf/slaves   添加slave1，slave2的IP地址 注意：要一行一个ip

10.将修改后的hadoop整个目录拷贝到其他机器上/home/hadoop/hadoop1.0目录  注意:hadoop用户要新建 

11.防火墙可能会引起master和salve之间的通讯，建议关闭  sudo iptables stop

12.在master机器上执行./hadoop/hadoop1.0/bin/hadoop namenode -format 格式化文件系统

13.在master上启动hadoop ./bin/start-all.sh 这个命令将会启动本机及其slave上的所有hadoop服务

14.常见问题

 jobtracker.info could only be replicated to 0 nodes, instead of 1 一般由防火墙导致可关闭防火墙，也可是在namenode中配置master 和 jobtracker 的ip时使用的是localhost ，将这两个改成namenode以及jobtracker本机的实际ip。

15.常用命令

	./hadoop namenode -format;./hadoop fs -mkdir input;./hadoop fs -put /home/xxx.txt input;./hadoop fs -ls input;./hadoop fs -cat input/*;

    ./hadoop dfs -rmr input;

    ./hadoop job -list

    ./jadoop job -kill jobid