---
layout: post
title: "HBASE 分布式安装使用"
category : hbase
tags : [mahout, bigData, hadoop, hbase]
---
author : xiajun

中文官方翻译文档:[http://abloz.com/hbase/book.html](http://abloz.com/hbase/book.html "hbase文档")

**安装说明:**

1.下载hbase安装包 [http://www.apache.org/dyn/closer.cgi/hbase/](http://www.apache.org/dyn/closer.cgi/hbase/ "hbase安装包")

2.将安装包放在 /home/hbase目录 解压

3.修改其conf目录下的hbase-site.xml

<?prettify lang=xml linenums=true?>
<pre class="prettyprint linenums" id="quine" style="border:4px solid #88c">
<xmp>
	<?xml version="1.0"?>        
	<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>        
	<configuration>        
	    <property>        
	         <name>hbase.rootdir</name>        
	         <value></value>        
	    </property>        
	    <property>        
	        <name>dfs.replication</name>        
	        <value>1</value>        
	    </property>        
	    <property>        
	        <name>hbase.cluster.distributed</name>        
	        <value>true</value>        
		</property>        
	    <property>        
	        <name>hbase.zookeeper.quorum</name><!-- zookeeper 服务ip 多个以 ,号分开 -->
	        <value>slaver1</value>        
	    </property>        
	    <property>        
	        <name>hbase.zookeeper.property.dataDir</name>        
	        <value>/home/xiajun/zookeeper-3.4.5/data</value><!--  zookeeper 存放文件的目录 可以在zookeeper安装目录下conf/zoo.cfg配置-->
	    </property>        
	    <property>        
	    <name>zookeeper.session.timeout</name>        
	    <value>60000</value>        
	    </property>        
	    <property>        
	      <name>hbase.zookeeper.property.clientPort</name><!-- 连接zookeeper的端口-->
	      <value>3181</value>        
	    </property>        
	</configuration>
</xmp></pre>

4.修改conf/regionservers文件，将所有datanode的ip写入，一行一个。比如：hbase 部署了3台机器，一台主，其他2台的ip要写入这个文件

5.修改conf/hbase-env.sh文件 

	export JAVA_HOME=/usr/servers/jdk1.6
	export HBASE_CLASSPATH=/home/hadoop-1.1.1/conf   //注意这里是hadoop的conf目录

6.将修改好的hbase复制到其他机器上。

7.启动hbase。在主节点机器上运行./bin/start-hbase.sh 其他机器也会被启动

8.使用shell  
>./bin/hbase shell

9.hbase 所有机器的系统时间要基本一致，否则会有问题。

10 导入数据到hbase

     数据文件列以tab键分割如：

     1    zhangsan    24    北京人
生成和表相同格式的文件

	./hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=',' -Dimporttsv.columns=HBASE_ROW_KEY,c:name,c:age,c:addres -Dimporttsv.bulk.output =/user/hbase/tmp/h_p  person /user/hbase/tmp/person.txt //注意这俩个地址是hdfs  其中person为表名,sepatator 为文本分割符
将上面生成的文件导入到数据库

	./hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /user/hbase/tmp/h_p  person //这个地址和上面的相同
11.常用命令

	list//查看所有表
    create 'tablename','coulmn_1','coulmn_2'  //创建表
    disable 'tablename'
    enable 'tablename'
    drop 'tablename'//删除表
    scan 'tablename'//查看表内容
    put 'tablename','keyname','coulmn_1:name','value'//添加内容
    get 'tablename','keyname',LIMIT => 10//查看前top天内容
    get 'tablename','keyname','coulmn_1:name'//指定列名查看
    delete 'tablename','keyname','coulmn_1:name' //只能删除一列
    deleteall 'tablename','keyname'//删除所有
    describe ’tablename' 查看表结构
12.一个无语的错误：Unable to find region for ,,99999999999999 after 10 tries.

    原因是我这保存hbase的数据目录中添加了一个临时目录，解决办法 删除这个目录。